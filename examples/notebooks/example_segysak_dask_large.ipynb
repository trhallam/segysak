{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using **dask**\n",
    "\n",
    "[dask](https://dask.org/) is a Python package build upon the scientific stack to enable scalling of Python through interactive sessions to multi-core and multi-node.\n",
    "\n",
    "Of particular relevance to **SEGY-SAK** is that `xrray.Dataset` loads naturally into `dask`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example use the Penobscot 3D available here:\n",
    "https://s3.us-east-2.amazonaws.com/seismic.euclidity.com/F3/f3_seismic_full.sgy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you first download it you will have to convert it to seisnc (NETCDF4)\n",
    "from segysak.segy import segy_converter\n",
    "segy_converter('f3_seismic_full.sgy', f3_seismic_full.seisnc, iline=189, xline=193, cdpx=181, cdpy=185)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "Here we import the plotting tools, `numpy` and setup the `dask.Client` which will auto start a `localcluster`. Printing the client returns details about the dashboard link and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from segysak import open_seisnc\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the dask cluster and client\n",
    "\n",
    "This starts a local cluster on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also scale the cluster to be a bit smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cluster.scale(2, memory='500mb')\n",
    "import time\n",
    "time.sleep(4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy loading from SEISNC using chunking\n",
    "\n",
    "By specifying the chunks argument to the `open_seisnc` command we can ask dask to fetch the data in chunks of size *n*. In this example the `iline` dimension will be chunked in groups of 100. The valid arguments to chunks depends on the dataset but any dimension can be used.\n",
    "\n",
    "Even though the seis of the dataset is `2.14GB` it hasn't yet been loaded into memory, not will `dask` load it entirely unless the operation demands it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisnc = open_seisnc('data/f3_seismic_full.SEISNC', chunks={'iline':200, 'xline':200})\n",
    "print(seisnc.seis.humanbytes)\n",
    "print(seisnc.chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what our dataset looks like. See that the variables are `dask.array`. This means they are references to the on disk data. The dimensions must be loaded so `dask` knows how to manage your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on SEISNC using `dask`\n",
    "\n",
    "In this simple example we calculate the mean, of the entire cube. If you check the dashboard (when running this example yourself). You can see the task graph and task stream execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = seisnc.data.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa-oh, the mean is what? Yeah, `dask` won't calculate anything until you ask it to. This means you can string computations together into a task graph for lazy evaluation. You can visualise the graph using `dask.visualize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires graphviz to be installed.\n",
    "#visualize(mean, filename='graph', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to get the mean try this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.compute().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with `dask`\n",
    "\n",
    "The lazy loading of data means we can plot what we want using `xarray` style slicing and `dask` will fetch only the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = seisnc.data.std().compute().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
    "\n",
    "elapsed1 = list()\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "iline = seisnc.sel(iline = 400).transpose('twt', 'xline').data\n",
    "xline = seisnc.sel(xline = 400).transpose('twt', 'iline').data\n",
    "zslice = seisnc.sel(twt = 1250, method='nearest').transpose('iline', 'xline').data\n",
    "\n",
    "# code you want to evaluate\n",
    "elapsed1.append(timeit.default_timer() - start_time)\n",
    "\n",
    "elapsed1.append(timeit.default_timer() - start_time)\n",
    "\n",
    "iline.plot(robust=True, ax=axs[0, 0], yincrease=False)\n",
    "xline.plot(robust=True, ax=axs[0, 1], yincrease=False)\n",
    "zslice.plot(robust=True, ax=axs[0, 2])\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "    cmap='seismic', aspect='auto', vmin=-std*3, vmax=std*3, interpolation='bicubic'\n",
    ")\n",
    "\n",
    "elapsed1.append(timeit.default_timer() - start_time)\n",
    "\n",
    "axs[1, 0].imshow(iline.values, **imshow_kwargs)\n",
    "axs[1, 0].set_title('iline')\n",
    "axs[1, 1].imshow(xline.values, **imshow_kwargs)\n",
    "axs[1, 1].set_title('xline')\n",
    "axs[1, 2].imshow(zslice.values, origin='lower', **imshow_kwargs)\n",
    "axs[1, 2].set_title('twt')\n",
    "\n",
    "elapsed1.append(timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming efficiently through a process and back to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stream back to disk by specifing an output at the end of the process. Don't mix dask collections\n",
    "like our `seisnc` and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisnc_std = (seisnc.data - seisnc.data.mean())/seisnc.data.std()\n",
    "seisnc_std = seisnc_std*10.0\n",
    "#print(seisnc_std.std().compute())\n",
    "seisnc_std.to_netcdf('test_dask5.seisnc', compute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bad - very bad when you already have a delayed object like xarray don't use the delayed decorator\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "@delayed(pure=True)\n",
    "def standardise_to_10(data):\n",
    "    return (data.data - data.data.mean())/data.data.std()\n",
    "\n",
    "#print(standardise_to_10(seisnc.data))\n",
    "\n",
    "s = standardise_to_10(seisnc)\n",
    "s = s.to_netcdf('test_dask.seisnc', compute=False)\n",
    "s.result().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a function to all traces individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to remove attrs which contain nan for output.\n",
    "seisnc.attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "def linear_gain(x, twt, gain_per_second):\n",
    "    x = x*twt*gain_per_second\n",
    "    return x\n",
    "    \n",
    "seisnc = seisnc.transpose('twt', 'iline', 'xline')\n",
    "    \n",
    "with_gain = da.apply_along_axis(\n",
    "    linear_gain, 0, seisnc.data, seisnc.twt.values, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With gain is now a dask array and is just a place holder with some information that dask can propergate forward into other processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign the data back to disk we must specify the dimensions like for normal assignments in `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisnc['data'] = (('twt', 'iline', 'xline'), with_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point the data still exists in the task graph and no computation as yet been done.\n",
    "seisnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can output the data to disk and complete the computation at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisnc.to_netcdf('gained.seisnc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets create a new lazy reference to the data and plot it up to see if the linear gain was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
    "\n",
    "gained = open_seisnc('gained.seisnc', chunks={'iline':100, 'xline':100})\n",
    "\n",
    "iline = gained.sel(iline = 400).transpose('twt', 'xline').data\n",
    "xline = gained.sel(xline = 400).transpose('twt', 'iline').data\n",
    "zslice = gained.sel(twt = 1250, method='nearest').transpose('iline', 'xline').data\n",
    "\n",
    "# code you want to evaluate\n",
    "iline.plot(robust=True, ax=axs[0, 0], yincrease=False)\n",
    "xline.plot(robust=True, ax=axs[0, 1], yincrease=False)\n",
    "zslice.plot(robust=True, ax=axs[0, 2])\n",
    "\n",
    "std = 400_000\n",
    "\n",
    "imshow_kwargs = dict(\n",
    "    cmap='seismic', aspect='auto', vmin=-std*3, vmax=std*3, interpolation='bicubic'\n",
    ")\n",
    "\n",
    "axs[1, 0].imshow(iline.values, **imshow_kwargs)\n",
    "axs[1, 0].set_title('iline')\n",
    "axs[1, 1].imshow(xline.values, **imshow_kwargs)\n",
    "axs[1, 1].set_title('xline')\n",
    "axs[1, 2].imshow(zslice.values, origin='lower', **imshow_kwargs)\n",
    "axs[1, 2].set_title('twt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
