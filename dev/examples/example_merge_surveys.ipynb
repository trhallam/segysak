{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a491fb3",
   "metadata": {},
   "source": [
    "# Merging Seismic Data Cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1351a2",
   "metadata": {},
   "source": [
    "Often we receive seismic data cubes which we wish to merge that have different geometries. This workflow will guide you through the process of merging two such cubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segysak import create3d_dataset\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "from segysak import open_seisnc, create_seismic_dataset\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "# start a dask client for processing\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df40dab",
   "metadata": {},
   "source": [
    "Creating some synthetic seismic surveys for us to play with. The online documentation uses a smaller example, but you can stress dask by commenting the dimension lines for smaller data and uncommenting the large desktop size volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115375f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# large desktop size merge\n",
    "# i1, i2, iN = 100, 750, 651\n",
    "# x1, x2, xN = 300, 1250, 951\n",
    "# t1, t2, tN = 0, 1848, 463\n",
    "# trans_x, trans_y = 10000, 2000\n",
    "\n",
    "# online example size merge\n",
    "i1, i2, iN = 650, 750, 101\n",
    "x1, x2, xN = 1150, 1250, 101\n",
    "t1, t2, tN = 0, 200, 201\n",
    "trans_x, trans_y = 9350, 1680\n",
    "\n",
    "iline = np.linspace(i1, i2, iN, dtype=int)\n",
    "xline = np.linspace(x1, x2, xN, dtype=int)\n",
    "twt = np.linspace(t1, t2, tN, dtype=int)\n",
    "\n",
    "affine_survey1 = Affine2D()\n",
    "affine_survey1.rotate_deg(20).translate(trans_x, trans_y)\n",
    "\n",
    "# create an empty dataset and empty coordinates\n",
    "survey_1 = create_seismic_dataset(twt=twt, iline=iline, xline=xline)\n",
    "survey_1[\"cdp_x\"] = ((\"iline\", \"xline\"), np.empty((iN, xN)))\n",
    "survey_1[\"cdp_y\"] = ((\"iline\", \"xline\"), np.empty((iN, xN)))\n",
    "\n",
    "stacked_iline = survey_1.iline.broadcast_like(survey_1.cdp_x).stack(\n",
    "    {\"ravel\": (..., \"xline\")}\n",
    ")\n",
    "stacked_xline = survey_1.xline.broadcast_like(survey_1.cdp_x).stack(\n",
    "    {\"ravel\": (..., \"xline\")}\n",
    ")\n",
    "\n",
    "points = np.dstack([stacked_iline, stacked_xline])\n",
    "points_xy = affine_survey1.transform(points[0])\n",
    "# put xy back in stacked and unstack into survey_1\n",
    "survey_1[\"cdp_x\"] = stacked_iline.copy(data=points_xy[:, 0]).unstack()\n",
    "survey_1[\"cdp_y\"] = stacked_iline.copy(data=points_xy[:, 1]).unstack()\n",
    "\n",
    "# and the same for survey_2 but with a different affine to survey 1\n",
    "affine_survey2 = Affine2D()\n",
    "affine_survey2.rotate_deg(120).translate(11000, 3000)\n",
    "\n",
    "survey_2 = create_seismic_dataset(twt=twt, iline=iline, xline=xline)\n",
    "survey_2[\"cdp_x\"] = ((\"iline\", \"xline\"), np.empty((iN, xN)))\n",
    "survey_2[\"cdp_y\"] = ((\"iline\", \"xline\"), np.empty((iN, xN)))\n",
    "\n",
    "stacked_iline = survey_1.iline.broadcast_like(survey_1.cdp_x).stack(\n",
    "    {\"ravel\": (..., \"xline\")}\n",
    ")\n",
    "stacked_xline = survey_1.xline.broadcast_like(survey_1.cdp_x).stack(\n",
    "    {\"ravel\": (..., \"xline\")}\n",
    ")\n",
    "\n",
    "points = np.dstack([stacked_iline, stacked_xline])\n",
    "points_xy = affine_survey2.transform(points[0])\n",
    "# put xy back in stacked and unstack into survey_1\n",
    "survey_2[\"cdp_x\"] = stacked_iline.copy(data=points_xy[:, 0]).unstack()\n",
    "survey_2[\"cdp_y\"] = stacked_iline.copy(data=points_xy[:, 1]).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0fcfca",
   "metadata": {},
   "source": [
    "Let's check that there is a bit of overlap between the two surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459501dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting every 10th line\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "survey_1_plot = plt.plot(\n",
    "    survey_1.cdp_x.values[::10, ::10], survey_1.cdp_y.values[::10, ::10], color=\"grey\"\n",
    ")\n",
    "survey_2_plot = plt.plot(\n",
    "    survey_2.cdp_x.values[::10, ::10], survey_2.cdp_y.values[::10, ::10], color=\"blue\"\n",
    ")\n",
    "# plt.aspect(\"equal\")\n",
    "plt.legend([survey_1_plot[0], survey_2_plot[0]], [\"survey_1\", \"survey_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482a360",
   "metadata": {},
   "source": [
    "Let's output these two datasets to disk so we can use lazy loading from seisnc. If the files are large, it's good practice to do this, because you will probably run out of memory.\n",
    "\n",
    "We are going to fill survey one with a values of 1 and survey 2 with a value of 2, just for simplicity in this example.\n",
    "We also tell the dtype to be `np.float32` to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7045414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out with new geometry\n",
    "survey_1[\"data\"] = (\n",
    "    (\"iline\", \"xline\", \"twt\"),\n",
    "    np.full((iN, xN, tN), 1, dtype=np.float32),\n",
    ")\n",
    "survey_1.seisio.to_netcdf(\"data/survey_1.seisnc\")\n",
    "del survey_1\n",
    "survey_2[\"data\"] = (\n",
    "    (\"iline\", \"xline\", \"twt\"),\n",
    "    np.full((iN, xN, tN), 2, dtype=np.float32),\n",
    ")\n",
    "survey_2.seisio.to_netcdf(\"data/survey_2.seisnc\")\n",
    "del survey_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db843ae",
   "metadata": {},
   "source": [
    "## How to merge two different geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0b33d",
   "metadata": {},
   "source": [
    "Let us reimport the surveys we created but in a chunked (lazy) way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ea422",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_1 = open_seisnc(\"data/survey_1.seisnc\", chunks=dict(iline=10, xline=10, twt=100))\n",
    "survey_2 = open_seisnc(\"data/survey_2.seisnc\", chunks=dict(iline=10, xline=10, twt=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7b3a8",
   "metadata": {},
   "source": [
    "Check that the survey is chunked by looking at the printout for our datasets. Lazy and chunked data will have a `dask.array<chunksize=` where the values are usually displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79f677",
   "metadata": {},
   "source": [
    "It will help with our other functions if we load the cdp_x and cdp_y locations into memory. This can be done using the `load()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479eba6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "survey_1[\"cdp_x\"] = survey_1[\"cdp_x\"].load()\n",
    "survey_1[\"cdp_y\"] = survey_1[\"cdp_y\"].load()\n",
    "survey_2[\"cdp_x\"] = survey_2[\"cdp_x\"].load()\n",
    "survey_2[\"cdp_y\"] = survey_2[\"cdp_y\"].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b1ca2",
   "metadata": {},
   "source": [
    "We will also need an affine transform which converts from il/xl on survey 2 to il/xl on survey 1. This will relate the two grids to each other. Fortunately affine transforms can be added together which makes this pretty straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68481fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilxl2_to_ilxl1 = (\n",
    "    survey_2.seis.get_affine_transform()\n",
    "    + survey_1.seis.get_affine_transform().inverted()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62413323",
   "metadata": {},
   "source": [
    "Let's check the transform to see if it makes sense. The colouring of our values by inline should be the same after the transform is applied. Cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting every 50th line\n",
    "\n",
    "n = 5\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "survey_1_plot = axs[0].scatter(\n",
    "    survey_1.cdp_x.values[::n, ::n],\n",
    "    survey_1.cdp_y.values[::n, ::n],\n",
    "    c=survey_1.iline.broadcast_like(survey_1.cdp_x).values[::n, ::n],\n",
    "    s=20,\n",
    ")\n",
    "survey_2_plot = axs[0].scatter(\n",
    "    survey_2.cdp_x.values[::n, ::n],\n",
    "    survey_2.cdp_y.values[::n, ::n],\n",
    "    c=survey_2.iline.broadcast_like(survey_2.cdp_x).values[::n, ::n],\n",
    "    s=20,\n",
    ")\n",
    "plt.colorbar(survey_1_plot, ax=axs[0])\n",
    "axs[0].set_aspect(\"equal\")\n",
    "\n",
    "axs[0].set_title(\"inline numbering before transform\")\n",
    "\n",
    "new_ilxl = ilxl2_to_ilxl1.transform(\n",
    "    np.dstack(\n",
    "        [\n",
    "            survey_2.iline.broadcast_like(survey_2.cdp_x).values.ravel(),\n",
    "            survey_2.xline.broadcast_like(survey_2.cdp_x).values.ravel(),\n",
    "        ]\n",
    "    )[0]\n",
    ").reshape((survey_2.iline.size, survey_2.xline.size, 2))\n",
    "\n",
    "survey_2.seis.calc_corner_points()\n",
    "s2_corner_points_in_s1 = ilxl2_to_ilxl1.transform(survey_2.attrs[\"corner_points\"])\n",
    "\n",
    "print(\"Min Iline:\", s2_corner_points_in_s1[:, 0].min(), survey_1.iline.min().values)\n",
    "min_iline_combined = min(\n",
    "    s2_corner_points_in_s1[:, 0].min(), survey_1.iline.min().values\n",
    ")\n",
    "print(\"Max Iline:\", s2_corner_points_in_s1[:, 0].max(), survey_1.iline.max().values)\n",
    "max_iline_combined = max(\n",
    "    s2_corner_points_in_s1[:, 0].max(), survey_1.iline.max().values\n",
    ")\n",
    "\n",
    "print(\"Min Xline:\", s2_corner_points_in_s1[:, 1].min(), survey_1.xline.min().values)\n",
    "min_xline_combined = min(\n",
    "    s2_corner_points_in_s1[:, 1].min(), survey_1.xline.min().values\n",
    ")\n",
    "print(\"Max Xline:\", s2_corner_points_in_s1[:, 1].max(), survey_1.xline.max().values)\n",
    "max_xline_combined = max(\n",
    "    s2_corner_points_in_s1[:, 1].max(), survey_1.xline.max().values\n",
    ")\n",
    "print(min_iline_combined, max_iline_combined, min_xline_combined, max_xline_combined)\n",
    "\n",
    "survey_1_plot = axs[1].scatter(\n",
    "    survey_1.cdp_x.values[::n, ::n],\n",
    "    survey_1.cdp_y.values[::n, ::n],\n",
    "    c=survey_1.iline.broadcast_like(survey_1.cdp_x).values[::n, ::n],\n",
    "    vmin=min_iline_combined,\n",
    "    vmax=max_iline_combined,\n",
    "    s=20,\n",
    "    cmap=\"hsv\",\n",
    ")\n",
    "\n",
    "\n",
    "survey_2_plot = axs[1].scatter(\n",
    "    survey_2.cdp_x.values[::n, ::n],\n",
    "    survey_2.cdp_y.values[::n, ::n],\n",
    "    c=new_ilxl[::n, ::n, 0],\n",
    "    vmin=min_iline_combined,\n",
    "    vmax=max_iline_combined,\n",
    "    s=20,\n",
    "    cmap=\"hsv\",\n",
    ")\n",
    "plt.colorbar(survey_1_plot, ax=axs[1])\n",
    "\n",
    "axs[1].set_title(\"inline numbering after transform\")\n",
    "axs[1].set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407c507",
   "metadata": {},
   "source": [
    "So we now have a transform that can convert ilxl from `survey_2` to ilxl from `survey_1` and we need to create a combined geometry for the merge. The dims need to cover the maximum range (inline, crossline) of two surveys. We are also going to use survey 1 as the base as we don't want to have to resample two cubes, although if you have a prefered geometry you could do that (custom affine transforms per survey required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dims\n",
    "iline_step = survey_1.iline.diff(\"iline\").mean().values\n",
    "xline_step = survey_1.xline.diff(\"xline\").mean().values\n",
    "\n",
    "# create the new dimensions\n",
    "new_iline_dim = np.arange(\n",
    "    int(min_iline_combined // iline_step) * iline_step,\n",
    "    int(max_iline_combined) + iline_step * 2,\n",
    "    iline_step,\n",
    "    dtype=np.int32,\n",
    ")\n",
    "new_xline_dim = np.arange(\n",
    "    int(min_xline_combined // xline_step) * xline_step,\n",
    "    int(max_xline_combined) + xline_step * 2,\n",
    "    xline_step,\n",
    "    dtype=np.int32,\n",
    ")\n",
    "\n",
    "# create a new empty dataset and a blank cdp_x for dims broadcasting\n",
    "survey_comb = create_seismic_dataset(\n",
    "    iline=new_iline_dim, xline=new_xline_dim, twt=survey_1.twt\n",
    ")\n",
    "survey_comb[\"cdp_x\"] = (\n",
    "    (\"iline\", \"xline\"),\n",
    "    np.empty((new_iline_dim.size, new_xline_dim.size)),\n",
    ")\n",
    "\n",
    "# calculate the x and y using the survey 1 affine which is our base grid and reshape to the dataset grid\n",
    "new_cdp_xy = affine_survey1.transform(\n",
    "    np.dstack(\n",
    "        [\n",
    "            survey_comb.iline.broadcast_like(survey_comb.cdp_x).values.ravel(),\n",
    "            survey_comb.xline.broadcast_like(survey_comb.cdp_x).values.ravel(),\n",
    "        ]\n",
    "    )[0]\n",
    ")\n",
    "new_cdp_xy_grid = new_cdp_xy.reshape((new_iline_dim.size, new_xline_dim.size, 2))\n",
    "\n",
    "# plot to check\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "survey_comb_plot = plt.plot(\n",
    "    new_cdp_xy_grid[:, :, 0], new_cdp_xy_grid[:, :, 1], color=\"red\", alpha=0.5\n",
    ")\n",
    "survey_1_plot = plt.plot(\n",
    "    survey_1.cdp_x.values[::10, ::10], survey_1.cdp_y.values[::10, ::10], color=\"grey\"\n",
    ")\n",
    "survey_2_plot = plt.plot(\n",
    "    survey_2.cdp_x.values[::10, ::10], survey_2.cdp_y.values[::10, ::10], color=\"blue\"\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    [survey_1_plot[0], survey_2_plot[0], survey_comb_plot[0]],\n",
    "    [\"survey_1\", \"survey_2\", \"survey_merged\"],\n",
    ")\n",
    "\n",
    "# put the new x and y in the empty dataset\n",
    "survey_comb[\"cdp_x\"] = ((\"iline\", \"xline\"), new_cdp_xy_grid[..., 0])\n",
    "survey_comb[\"cdp_y\"] = ((\"iline\", \"xline\"), new_cdp_xy_grid[..., 1])\n",
    "survey_comb = survey_comb.set_coords((\"cdp_x\", \"cdp_y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e25ed9",
   "metadata": {},
   "source": [
    "## Resampling `survey_2` to `survey_1` geometry\n",
    "\n",
    "Resampling one dataset to another requires us to tell Xarray/dask where we want the new traces to be. First we can convert the x and y coordinates of the combined survey to the il xl of survey 2 using the affine transform of survey 2. This transform works il/xl to x and y and therefore we need it inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2_new_ilxl_loc = affine_survey2.inverted().transform(new_cdp_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f568daf",
   "metadata": {},
   "source": [
    "We then need to create a sampling DataArray. If we passed the iline and cross line locations from the previous cell unfortunately Xarray would broadcast the inline and xline values against each other. The simplest way is to create a new stacked flat dimension which we can unstack into a cube later.\n",
    "\n",
    "We also need to give it unique names so xarray doesn't confuse the new dimensions with the old dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6295d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = (\n",
    "    survey_comb.rename(  # use the combined survey\n",
    "        {\"iline\": \"new_iline\", \"xline\": \"new_xline\"}\n",
    "    )  # renaming inline and xline so they don't confuse xarray\n",
    "    .stack(\n",
    "        {\"flat\": (\"new_iline\", \"new_xline\")}\n",
    "    )  # and flatten the iline and xline axes using stack\n",
    "    .flat  # return just the flat coord object which is multi-index (so we can unstack later)\n",
    ")\n",
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of new coordinates to sample to. We use flat here because it will easily allow us to\n",
    "# unstack the data after interpolation. It's necessary to use this flat dataset, otherwise xarray will try to\n",
    "# interpolate on the cartesian product of iline and xline, which isn't really what we want.\n",
    "\n",
    "resampling_data_arrays = dict(\n",
    "    iline=xr.DataArray(survey_2_new_ilxl_loc[:, 0], dims=\"flat\", coords={\"flat\": flat}),\n",
    "    xline=xr.DataArray(survey_2_new_ilxl_loc[:, 1], dims=\"flat\", coords={\"flat\": flat}),\n",
    ")\n",
    "\n",
    "resampling_data_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97775b32",
   "metadata": {},
   "source": [
    "The resampling can take a while with larger cubes, so it is good to use dask and to output the cube to disk at this step.\n",
    "When using dask for processing it is better to output to disk regularly, as this will improve how your code runs and the overall memory usage.\n",
    "\n",
    "*If you are executing this exmample locally, the task progress can be viewed by opening the dask [client](http://localhost:8787/status).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2_resamp = survey_2.interp(**resampling_data_arrays)\n",
    "survey_2_resamp_newgeom = (\n",
    "    survey_2_resamp.drop_vars((\"iline\", \"xline\"))\n",
    "    .unstack(\"flat\")\n",
    "    .rename({\"new_iline\": \"iline\", \"new_xline\": \"xline\"})\n",
    "    .data\n",
    ")\n",
    "survey_2_resamp_newgeom.to_netcdf(\"data/survey_2_1.nc\", compute=True, engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d2e70",
   "metadata": {},
   "source": [
    "## Combining Cubes\n",
    "\n",
    "The last step is combining the cube is to load the two datasets to be combined and concatenate them together along a new axis. This will simplify reduction processes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2_resamp_newgeom = xr.open_dataarray(\n",
    "    \"data/survey_2_1.nc\", chunks=dict(iline=10, xline=10, twt=100), engine=\"h5netcdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_2_resamp_newgeom.expand_dims({\"survey\": [2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate survey with new dimension \"survey\".\n",
    "survey_comb[\"data\"] = xr.concat([survey_1.data, survey_2_resamp_newgeom], \"survey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec469561",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aae5a1",
   "metadata": {},
   "source": [
    "We can check the merged surveys by looking at some plots. If we select just the first survey the values will be 1. If we select just the second survey the values will be 2. And if we take the mean along the survey dimension, then where the surveys overlap the values will be 1.5.\n",
    "\n",
    "For seismic data, a better form of conditioning and reduction might be required for merging traces together to ensure a smoother seam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = survey_comb.sel(xline=1190)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(30, 10))\n",
    "\n",
    "sel.isel(survey=0).data.T.plot(ax=axs[0], yincrease=False, vmin=1, vmax=2)\n",
    "sel.isel(survey=1).data.T.plot(ax=axs[1], yincrease=False, vmin=1, vmax=2)\n",
    "sel.data.mean(\"survey\").T.plot(ax=axs[2], yincrease=False, vmin=1, vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_comb.twt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8692e0",
   "metadata": {},
   "source": [
    "And if we inspect a time slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = survey_comb.sel(twt=100)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(30, 10))\n",
    "\n",
    "sel.isel(survey=0).data.T.plot(ax=axs[0], yincrease=False, vmin=1, vmax=2)\n",
    "sel.isel(survey=1).data.T.plot(ax=axs[1], yincrease=False, vmin=1, vmax=2)\n",
    "sel.data.mean(\"survey\").T.plot(ax=axs[2], yincrease=False, vmin=1, vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3aa38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
